

ğŸ“˜ RAG PDF Question Answering System (MLOps Integrated)

A Retrieval-Augmented Generation system using Mistral LLM, FAISS Vector Search, and Streamlit UI

ğŸš€ Overview

This project implements a complete Retrieval-Augmented Generation (RAG) pipeline that allows users to:

âœ”ï¸ Upload one or multiple PDF files
âœ”ï¸ Automatically extract text (pdfplumber + OCR for scanned PDFs)
âœ”ï¸ Chunk & embed text using Sentence Transformers
âœ”ï¸ Store embeddings in a FAISS vector database
âœ”ï¸ Retrieve relevant chunks using cosine similarity
âœ”ï¸ Generate accurate answers using Mistral LLM
âœ”ï¸ Interact through a clean Streamlit web interface

This system follows MLOps best practices, making it modular, reusable, and production-ready.

ğŸ§± Architecture

PDF Upload
   â†“
PDF Text Extraction (pdfplumber + OCR)
   â†“
Text Chunking
   â†“
Embedding Generation (SentenceTransformers)
   â†“
FAISS Vector Store (Cosine Similarity Search)
   â†“
Retriever (Top-k Relevant Chunks)
   â†“
Mistral LLM Answer Generation
   â†“
Streamlit UI

ğŸ§° Features
ğŸ”¹ PDF Processing

Extracts text from digital PDFs using pdfplumber

Uses Tesseract OCR for scanned PDFs

Stores extracted text in data/docs/

ğŸ”¹ Chunking

Splits long documents into 300â€“500 character segments

Ensures meaningful, context-preserving retrieval

ğŸ”¹ Embedding Generation

Uses sentence-transformers/all-MiniLM-L6-v2

Creates 384-dimensional semantic embeddings

ğŸ”¹ FAISS Vector Database

Fast vector similarity search

Stores all embeddings

Performs cosine similarity search

ğŸ”¹ RAG Pipeline

Embeds user query

Retrieves top-k relevant chunks

Passes them to Mistral LLM

Generates accurate, context-grounded answers

ğŸ”¹ Streamlit Interface

Upload PDFs

Process documents

Ask natural-language questions

View generated answers

ğŸ› ï¸ Installation
1. Clone repo
   git clone https://github.com/<your-username>/<repo>.git
cd <repo>
python3 -m venv .mlops_env
source .mlops_env/bin/activate
pip install -r requirements.txt
streamlit run app.py

How to Use
1ï¸âƒ£ Upload PDFs

Supports multiple files.

2ï¸âƒ£ Process PDFs

This step performs:

Text extraction

OCR (if scanned)

Chunking

Embeddings

FAISS index creation

3ï¸âƒ£ Ask Questions

Ask any question related to the uploaded PDF contents.

Example:

What is the conclusion of the document?

ğŸ” Retrieval Score Used

We use cosine similarity for retrieval.

FAISS performs inner-product search on normalized vectors:

cosine_similarity=qâ‹…d
cosine_similarity=qâ‹…d

Top-k most similar chunks are retrieved and passed to the LLM.

ğŸ“Š MLOps Components
âœ”ï¸ Loguru Logging

Tracks:

PDF â†’ text extraction

Embeddings generation

Vector indexing

Query processing

âœ”ï¸ MLflow Tracking (Optional)

Logs:

Chunk count

Processing time

Embedding model

LLM model used

âœ”ï¸ Modular Pipeline

Each stage (extraction, chunking, embeddings, retrieval, generation) is isolated and reusable.

Future Enhancements

Incremental FAISS indexing

Metadata-based search

Cloud deployment (Hugging Face / AWS)

Cross-encoder re-ranking

GPU inference

Chat memory

ğŸ Conclusion

This project demonstrates a complete, production-ready RAG system with:

PDF ingestion

Text & OCR extraction

Embedding generation

Vector search

LLM-based question answering

Streamlit UI

MLOps-ready architecture

It is modular, scalable, and can be deployed or extended easily.
